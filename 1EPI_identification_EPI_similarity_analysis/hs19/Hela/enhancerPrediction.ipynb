{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate enhancer、eRNA、EPI for Hela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pyBigWig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction define. if eRNA intersect with promoter, return False. else return True\n",
    "def ifFilter(row):\n",
    "    try:\n",
    "        if (row['eRNA_start'] >= row['promoter_start']) & (row['eRNA_start'] <= row['promoter_end']):\n",
    "            return True\n",
    "        elif (row['eRNA_end'] >= row['promoter_start']) & (row['eRNA_end'] <= row['promoter_end']):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        try:\n",
    "            if (row['enhancer_start'] >= row['promoter_start']) & (row['enhancer_start'] <= row['promoter_end']):\n",
    "                return True\n",
    "            elif (row['enhancer_end'] >= row['promoter_start']) & (row['enhancer_end'] <= row['promoter_end']):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            raise KeyError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enhancer identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence data download\n",
    "cmd = f\"bash download.sh\"\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histone modification ChIP-seq call peak\n",
    "files = ['H3K4me1_r2.bam', 'H3K4me1_r1.bam', 'H3K27ac_r2.bam', 'H3K27ac_r1.bam']\n",
    "for file in files:\n",
    "    inputFile = 'control_r1.bam' if 'r1' in file else 'control_r2.bam'\n",
    "    cmd = f\"sicer -t {file} -c {inputFile} -s hg19 -fdr 0.05 -cpu 20 -o .\"\n",
    "    subprocess.run(cmd, shell=True)\n",
    "\n",
    "# Get standard-format broadPeak file from sicer result\n",
    "files = [x for x in os.listdir() if (x.endswith('-W200-G600.scoreisland') and 'H3K' in x)]\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, sep='\\t', header=None)\n",
    "    df.insert(3, 'peakName', [f'peak{x}' for x in range(1, df.shape[0]+1)])\n",
    "    df['strand'] = '.'\n",
    "    df['signalValue'] = df[3]\n",
    "    df['pValue'] = df[3]\n",
    "    df['qValue'] = df[3]\n",
    "    df.to_csv(file.replace('-W200-G600.scoreisland', '.broadPeak'), sep='\\t', header=None, index=False)\n",
    "\n",
    "# Use idr to combine different replicates\n",
    "files = [x for x in os.listdir() if (x.endswith('.broadPeak') and 'H3K' in x and 'r1' in x)]\n",
    "for file in files:\n",
    "    file_rep2 = file.replace('r1', 'r2')\n",
    "    outfile = file.replace('r1',  'idr')\n",
    "    cmd = f'''idr --samples {file} {file_rep2} --input-file-type broadPeak \\\n",
    "        --rank q.value --output-file {outfile} --output-file-type broadPeak \\\n",
    "            --plot --log-output-file {outfile}.log'''\n",
    "    subprocess.run(cmd, shell=True)\n",
    "\n",
    "# Filter idr result with threshold as 0.1\n",
    "files = [x for x in os.listdir() if (x.endswith('.broadPeak') and 'H3K' in x and 'idr' in x)]\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, sep='\\t', header=None)\n",
    "    df = df[df[4]> int(-125 *  np.log2(0.1))]\n",
    "    df.to_csv(file.replace('.broadPeak', '_filter.broadPeak'), sep='\\t', header=None, index=False)\n",
    "\n",
    "# H3K4me1 H3K27ac intersection calculation\n",
    "H3K4me1_file = [x for x in os.listdir() if (x.endswith('_filter.broadPeak') and 'H3K4me1' in x and 'idr' in x)][0]\n",
    "H3K27ac_file = [x for x in os.listdir() if (x.endswith('_filter.broadPeak') and 'H3K27ac' in x and 'idr' in x)][0]\n",
    "cmd = f\"bedtools intersect -a {H3K4me1_file} -b {H3K27ac_file} > H3K4me1_H3K27ac_intersect.bed\"\n",
    "subprocess.run(cmd, shell=True)\n",
    "\n",
    "# Retain H3K4me1 H3K27ac intersection part which show lower H3K4me3 histone modification signal. Get primary enhancer.\n",
    "H3K4me1_bam = [x for x in os.listdir() if (x.endswith('.bam') and 'H3K4me1' in x)]\n",
    "for file in H3K4me1_bam:\n",
    "    if f\"{file}.bai\" in os.listdir():\n",
    "        continue\n",
    "    cmd = f\"samtools index -@ 20 {file}\"\n",
    "    subprocess.run(cmd, shell=True)\n",
    "cmd = f'''bamCompare -b1 {H3K4me1_bam[0]} -b2 {H3K4me1_bam[1]} --outFileName H3K4me1_all.bw \\\n",
    "          --normalizeUsing CPM --binSize 10 --operation add --numberOfProcessors 20 --scaleFactorsMethod None'''\n",
    "subprocess.run(cmd, shell=True)\n",
    "H3K4me3_bam = [x for x in os.listdir() if (x.endswith('.bam') and 'H3K4me3' in x)]\n",
    "for file in H3K4me3_bam:\n",
    "    if f\"{file}.bai\" in os.listdir():\n",
    "        continue\n",
    "    cmd = f\"samtools index -@ 20 {file}\"\n",
    "    subprocess.run(cmd, shell=True)\n",
    "cmd = f'''bamCompare -b1 {H3K4me3_bam[0]} -b2 {H3K4me3_bam[1]} --outFileName H3K4me3_all.bw \\\n",
    "            --normalizeUsing CPM --binSize 10 --operation add --numberOfProcessors 20 --scaleFactorsMethod None'''\n",
    "subprocess.run(cmd, shell=True)\n",
    "me1BW = pyBigWig.open('H3K4me1_all.bw')\n",
    "me3BW = pyBigWig.open('H3K4me3_all.bw')\n",
    "def ifRetain(row, me1BW, me3BW, me1ScoreAll=1, me3ScoreAll=1):\n",
    "    chr = row[0]\n",
    "    start = row[1]\n",
    "    end = row[2]\n",
    "    me1Score = np.array(me1BW.stats(chr, start, end, type='sum'))[0] / me1ScoreAll * pow(10, 6)\n",
    "    me3Score = np.array(me3BW.stats(chr, start, end, type='sum'))[0] / me3ScoreAll * pow(10, 6)\n",
    "    if me1Score > 1.5 * me3Score:\n",
    "        return True, me1Score, me3Score\n",
    "    else:\n",
    "        return False, me1Score, me3Score\n",
    "df = pd.read_csv('H3K4me1_H3K27ac_intersect.bed', sep='\\t', header=None)\n",
    "df['result'] = df.apply(ifRetain, axis=1, args=(me1BW, me3BW))\n",
    "df[['retain', 'me1Score', 'me3Score']] = df['result'].apply(pd.Series)\n",
    "me1BW.close()\n",
    "me3BW.close()\n",
    "df[df['retain']][[0,1,2]].to_csv('enhancer_primary.bed', sep='\\t', header=None, index=False)\n",
    "\n",
    "# DNase-seq data process to get broadPeak.\n",
    "files = [x for x in os.listdir() if ((x.endswith('.bam')) and ('DNase' in x))]\n",
    "for file in files:\n",
    "    cmd = f\"sicer -t {file} -s hg19 -fdr 0.05 -cpu 20 -o .\"\n",
    "    subprocess.run(cmd, shell=True)\n",
    "files = [x for x in os.listdir() if (x.endswith('-W200-G600.scoreisland') and 'DNase' in x)]\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, sep='\\t', header=None)\n",
    "    df.insert(3, 'peakName', [f'peak{x}' for x in range(1, df.shape[0]+1)])\n",
    "    df['strand'] = '.'\n",
    "    df['signalValue'] = df[3]\n",
    "    df['pValue'] = df[3]\n",
    "    df['qValue'] = df[3]\n",
    "    df.to_csv(file.replace('-W200-G600.scoreisland', '.broadPeak'), sep='\\t', header=None, index=False)\n",
    "\n",
    "# Filter primary enhancer with its DNase broadPeak. Obtain final enhancer.\n",
    "DNase_file = [x for x in os.listdir() if (x.endswith('.broadPeak') and 'DNase' in x)][0]\n",
    "cmd = f\"bedtools intersect -a enhancer_primary.bed -b {DNase_file} -u -f 0.5 -F 0.5 -e > enhancer.bed\"\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eRNA identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROseq data process\n",
    "\n",
    "# Use Fastq-dump to convert SRA data to fastq data.\n",
    "singleSraList = [x for x in os.listdir() if x.endswith('single.sra')]\n",
    "for singleSra in singleSraList:\n",
    "    cmd = f\"parallel-fastq-dump --sra-id {singleSra} -t 20 -O . --gzip\"\n",
    "    subprocess.run(cmd, shell=True)\n",
    "\n",
    "# Use trim-galore to cut adapter and filter low quality reads.\n",
    "files = [x for x in os.listdir() if x.endswith('single.fastq.gz')]\n",
    "for file in files:\n",
    "    cmd = f\"trim_galore -q 20 --max_n 4 --phred33 --stringency 3 -j 4 -o . {file}\"\n",
    "    subprocess.run(cmd, shell=True)\n",
    "\n",
    "# Use bwa mem to align filtered reads with genome. Remove duplication with SAMtools.\n",
    "files = [x for x in os.listdir() if x.endswith('_trimmed.fq.gz')]\n",
    "refGene = '/home/limh/Reference_Genome/Homo/hg19/BWA/genome.fa'\n",
    "for file in files:\n",
    "    outfile = file.replace('_single_trimmed.fq.gz', '_sort.bam')\n",
    "    outfile_rmdup = file.replace('_single_trimmed.fq.gz', '_sort_rmdup.bam')\n",
    "    cmd = f\"bwa mem -t 20 -M {refGene} {file} |samtools view -@ 1 -q 10 -hb -F 3852 -S |samtools sort -@ 10 -o {outfile} -\"\n",
    "    subprocess.run(cmd, shell=True)\n",
    "    cmd = f\"samtools rmdup -s {outfile} {outfile_rmdup}\"\n",
    "    subprocess.run(cmd, shell=True)\n",
    "\n",
    "# Call peak with Homer\n",
    "fileList = [x for x in os.listdir() if (x.endswith('_sort_rmdup.bam') and 'GROseq' in x)]\n",
    "bamFiles = '\\t'.join([x for x in fileList])\n",
    "cmd = f\"makeTagDirectory GROseq_Hela/ -genome /home/limh/Reference_Genome/Homo/hg19/genome.fa -checkGC {bamFiles}\"\n",
    "subprocess.run(cmd, shell=True)\n",
    "folderList = ['GROseq_Hela']\n",
    "for folder in folderList:\n",
    "    cmd = f'''findPeaks {folder} -style groseq -o auto -tssSize 250 -minBodySize 250 \\\n",
    "              -tssFold 4 -bodyFold 3 -fragLength 50 -pseudoCount 1 -confPvalue 1.00e-05'''\n",
    "    subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eRNA identification\n",
    "\n",
    "# get the nascent transcripts identifyied by Homer from GRO-seq\n",
    "df = pd.read_csv('/home/limh/epSameTransposon/Homo/eRnaHela/GROseq_Hela/transcripts.gtf', sep='\\t', header=None)\n",
    "df[[0,3,4,7,5,6]].to_csv('transcripts.bed', sep='\\t', header=None, index=False)\n",
    "\n",
    "# Get the nascent transcripts lies in enhancer region.\n",
    "cmd = f\"bedtools intersect -a transcripts.bed -b enhancer.bed -u -f 0.8 > transcripts_InEnhancer.bed\"\n",
    "subprocess.run(cmd, shell=True)\n",
    "cmd = f\"bedtools merge -s -d -250 -c 4,5,6 -o first,mean,first -i transcripts_InEnhancer.bed > eRNA_primary.bed\"\n",
    "subprocess.run(cmd, shell=True)\n",
    "\n",
    "# Retrain the nascent transcripts which shows proper length: 500bp ~ 5000bp.\n",
    "df = pd.read_csv('eRNA_primary.bed', sep='\\t', header=None)\n",
    "df = df[(df[2]-df[1]).between(200, 5000)]\n",
    "df[3] = [f\"eRNA{x}\" for x in range(1, len(df)+1)]\n",
    "df.to_csv('eRNA.bed', sep='\\t', header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPI construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eRNA promoter interaction construction\n",
    "df = pd.read_csv('GSE63525_HeLa_Arrowhead_domainlist.txt', sep='\\t')\n",
    "df['chr1'] = 'chr' + df['chr1']\n",
    "df[['chr1', 'x1', 'x2']].to_csv('TAD.bed', sep='\\t', header=None, index=None)\n",
    "cmd = f\"bedtools intersect -a promoter.bed -b TAD.bed -wo -f 0.8 -F 0.8 -e > promoter_TAD_intersectWo.txt\"\n",
    "subprocess.run(cmd, shell=True)\n",
    "cmd = f\"bedtools intersect -a eRNA.bed -b TAD.bed -wo -f 0.8 -F 0.8 -e > eRNA_TAD_intersectWo.txt\"\n",
    "subprocess.run(cmd, shell=True)\n",
    "promoter_TAD_intersectWo_df = pd.read_csv('promoter_TAD_intersectWo.txt', sep='\\t', header=None)\n",
    "promoter_TAD_intersectWo_df.columns = ['promoter_chr', 'promoter_start', 'promoter_end', 'promoter_name', 'promoter_score', 'promoter_strand',\n",
    "                                       'TAD_chr', 'TAD_start', 'TAD_end', 'intersect']\n",
    "eRNA_TAD_intersectWo_df = pd.read_csv('eRNA_TAD_intersectWo.txt', sep='\\t', header=None)\n",
    "eRNA_TAD_intersectWo_df.columns = ['eRNA_chr', 'eRNA_start', 'eRNA_end', 'eRNA_name', 'eRNA_score', 'eRNA_strand',\n",
    "                                   'TAD_chr', 'TAD_start', 'TAD_end', 'intersect']\n",
    "epi_df = pd.merge(eRNA_TAD_intersectWo_df, promoter_TAD_intersectWo_df,\n",
    "                  on = ['TAD_chr', 'TAD_start', 'TAD_end'], how='inner')\n",
    "\n",
    "# EPI filter\n",
    "epi_df['filter'] = epi_df.apply(ifFilter, axis=1)\n",
    "epi_filter_df = epi_df[epi_df['filter']==False]\n",
    "epi_filter_df['epi_name'] = epi_filter_df['eRNA_name'].str.cat(epi_filter_df['promoter_name'], sep=';')\n",
    "\n",
    "# save EPI result\n",
    "epi_filter_df[['eRNA_chr', 'eRNA_start', 'eRNA_end', 'promoter_chr', 'promoter_start', 'promoter_end',\n",
    "               'epi_name', 'eRNA_score', 'eRNA_strand', 'promoter_strand']].to_csv('epi.bedpe', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhancer-promoter interaction construction\n",
    "cmd = f\"bedtools intersect -a enhancer.bed -b TAD.bed -wo -f 0.8 -F 0.8 -e > enhancer_TAD_intersectWo.txt\"\n",
    "subprocess.run(cmd, shell=True)\n",
    "promoter_TAD_intersectWo_df = pd.read_csv('promoter_TAD_intersectWo.txt', sep='\\t', header=None)\n",
    "promoter_TAD_intersectWo_df.columns = ['promoter_chr', 'promoter_start', 'promoter_end', 'promoter_name', 'promoter_score', 'promoter_strand',\n",
    "                                       'TAD_chr', 'TAD_start', 'TAD_end', 'intersect']\n",
    "enhancer_TAD_intersectWo_df = pd.read_csv('enhancer_TAD_intersectWo.txt', sep='\\t', header=None)\n",
    "enhancer_TAD_intersectWo_df.insert(3, 'enhancer_name', [f\"enhancer{x}\" for x in range(1, len(enhancer_TAD_intersectWo_df)+1)])\n",
    "enhancer_TAD_intersectWo_df.insert(4, 'enhancer_score', 1)\n",
    "enhancer_TAD_intersectWo_df.insert(5, 'enhancer_strand', '.')\n",
    "enhancer_TAD_intersectWo_df.columns = ['enhancer_chr', 'enhancer_start', 'enhancer_end', 'enhancer_name', 'enhancer_score', 'enhancer_strand',\n",
    "                                   'TAD_chr', 'TAD_start', 'TAD_end', 'intersect']\n",
    "epi_df = pd.merge(enhancer_TAD_intersectWo_df, promoter_TAD_intersectWo_df,\n",
    "                  on = ['TAD_chr', 'TAD_start', 'TAD_end'], how='inner')\n",
    "# EPI过滤及补充信息\n",
    "epi_df['filter'] = epi_df.apply(ifFilter, axis=1)\n",
    "epi_filter_df = epi_df[epi_df['filter']==False]\n",
    "epi_filter_df['epi_name'] = epi_filter_df['enhancer_name'].str.cat(epi_filter_df['promoter_name'], sep=';')\n",
    "\n",
    "# EPI结果保存\n",
    "epi_filter_df[['enhancer_chr', 'enhancer_start', 'enhancer_end', 'promoter_chr', 'promoter_start', 'promoter_end',\n",
    "               'epi_name', 'enhancer_score', 'enhancer_strand', 'promoter_strand']].to_csv('enhancerPI.bedpe', sep='\\t', header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
